{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61075,
     "status": "ok",
     "timestamp": 1605660580203,
     "user": {
      "displayName": "‍김수영[학생](공과대학 산업경영공학과)",
      "photoUrl": "https://lh4.googleusercontent.com/--jvnwCNAQF4/AAAAAAAAAAI/AAAAAAAABPo/sXLQKwZm7fw/s64/photo.jpg",
      "userId": "00210890095209318843"
     },
     "user_tz": -540
    },
    "id": "-1ngbVAX3F7P",
    "outputId": "51d99bf8-ca91-4ae0-ce23-5b9acd6c50d8"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-adff2ef1463c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from google.colab import drive\n",
    "from keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "look_back = 5\n",
    "columns = 2\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back):\n",
    "        a = dataset[i:(i + look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back][0])\n",
    "    return np.array(dataX), np.array(dataY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1439,
     "status": "ok",
     "timestamp": 1605671962472,
     "user": {
      "displayName": "‍김수영[학생](공과대학 산업경영공학과)",
      "photoUrl": "https://lh4.googleusercontent.com/--jvnwCNAQF4/AAAAAAAAAAI/AAAAAAAABPo/sXLQKwZm7fw/s64/photo.jpg",
      "userId": "00210890095209318843"
     },
     "user_tz": -540
    },
    "id": "YbaMuPfp3F7Z"
   },
   "outputs": [],
   "source": [
    "# file loader\n",
    "data1 = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/stock_dataset/rnn/Cluster0_train_log.CSV',index_col=\"Date\",encoding='cp949')\n",
    "data2 = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/stock_dataset/rnn/Cluster0_test_log.CSV',index_col=\"Date\",encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "open=pd.read_csv('kospi_price_data_open.csv',index_col=0)\n",
    "close=pd.read_csv('kospi_price_data_close.csv',index_col=0)\n",
    "high=pd.read_csv('kospi_price_data_high.csv',index_col=0)\n",
    "low=pd.read_csv('kospi_price_data_low.csv',index_col=0)\n",
    "volume=pd.read_csv('kospi_price_data_volume.csv',index_col=0)\n",
    "open=open.T\n",
    "close=close.T\n",
    "high=high.T\n",
    "low=low.T\n",
    "volume=volume.T\n",
    "ma=close['삼성전자'].rolling(window=20).mean()\n",
    "ma=ma.fillna(ma.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 610,
     "status": "ok",
     "timestamp": 1605671965033,
     "user": {
      "displayName": "‍김수영[학생](공과대학 산업경영공학과)",
      "photoUrl": "https://lh4.googleusercontent.com/--jvnwCNAQF4/AAAAAAAAAAI/AAAAAAAABPo/sXLQKwZm7fw/s64/photo.jpg",
      "userId": "00210890095209318843"
     },
     "user_tz": -540
    },
    "id": "ofbftS2pCfwj"
   },
   "outputs": [],
   "source": [
    "col=list(open.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEdRybf0DvGX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 655,
     "status": "ok",
     "timestamp": 1605611888640,
     "user": {
      "displayName": "‍김수영[학생](공과대학 산업경영공학과)",
      "photoUrl": "https://lh4.googleusercontent.com/--jvnwCNAQF4/AAAAAAAAAAI/AAAAAAAABPo/sXLQKwZm7fw/s64/photo.jpg",
      "userId": "00210890095209318843"
     },
     "user_tz": -540
    },
    "id": "uusvH2xp3F7d",
    "outputId": "4f76bdcf-13a8-42b5-e87d-2e9eb923a9b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 19\n"
     ]
    }
   ],
   "source": [
    "# convert nparray # split train, test\n",
    "train = pandf_train.values\n",
    "train.astype('float32')\n",
    "test = pandf_test.values\n",
    "test.astype('float32')\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 622,
     "status": "ok",
     "timestamp": 1605611890607,
     "user": {
      "displayName": "‍김수영[학생](공과대학 산업경영공학과)",
      "photoUrl": "https://lh4.googleusercontent.com/--jvnwCNAQF4/AAAAAAAAAAI/AAAAAAAABPo/sXLQKwZm7fw/s64/photo.jpg",
      "userId": "00210890095209318843"
     },
     "user_tz": -540
    },
    "id": "3YdGxiqF3F7i",
    "outputId": "82cec2a2-9fbe-44df-c123-ead40111ba0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03815789 0.01981506 0.04946524 0.04138852 0.06176084 0.04118404\n",
      " 0.03535353 0.0278481  0.03826531 0.02515723 0.02038217 0.02051282\n",
      " 0.03807107 0.03771131]\n"
     ]
    }
   ],
   "source": [
    "# create dataset for learning\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "print(testY)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], look_back, columns))\n",
    "testX = np.reshape(testX, (testX.shape[0], look_back, columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16662,
     "status": "ok",
     "timestamp": 1605611908475,
     "user": {
      "displayName": "‍김수영[학생](공과대학 산업경영공학과)",
      "photoUrl": "https://lh4.googleusercontent.com/--jvnwCNAQF4/AAAAAAAAAAI/AAAAAAAABPo/sXLQKwZm7fw/s64/photo.jpg",
      "userId": "00210890095209318843"
     },
     "user_tz": -540
    },
    "id": "VsvThhjU3F7o",
    "outputId": "ba98884b-0070-4727-9491-e3b1df039768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0063\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc4fa498fd0>"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple lstm network learning\n",
    "model = Sequential()\n",
    "model.add(LSTM(5, input_shape=(look_back, columns)))   \n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=50, batch_size=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 711,
     "status": "ok",
     "timestamp": 1605612892047,
     "user": {
      "displayName": "‍김수영[학생](공과대학 산업경영공학과)",
      "photoUrl": "https://lh4.googleusercontent.com/--jvnwCNAQF4/AAAAAAAAAAI/AAAAAAAABPo/sXLQKwZm7fw/s64/photo.jpg",
      "userId": "00210890095209318843"
     },
     "user_tz": -540
    },
    "id": "kdtvAmnj9rAN",
    "outputId": "e03d6cbf-c3e4-4157-f98c-e7a61fcf5f42"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-aaa5be3e45ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#print(testPredict)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#print(testY)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtestPredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtestScore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestPredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#print(testPredict)\n",
    "#print(testY)\n",
    "testPredict = model.predict(testX)\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "sum=0\n",
    "for i in range(len(testY)):\n",
    "  sum+=abs((testY[i]-testPredict[i])/testY[i])\n",
    "\n",
    "mape=100*sum/int(len(testY))\n",
    "print('MAPE :',float(mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 1310,
     "status": "ok",
     "timestamp": 1605671403094,
     "user": {
      "displayName": "‍김수영[학생](공과대학 산업경영공학과)",
      "photoUrl": "https://lh4.googleusercontent.com/--jvnwCNAQF4/AAAAAAAAAAI/AAAAAAAABPo/sXLQKwZm7fw/s64/photo.jpg",
      "userId": "00210890095209318843"
     },
     "user_tz": -540
    },
    "id": "xrTAEDwm3F7w",
    "outputId": "c0018197-505a-495a-d35a-2ff4dc1aff90"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d94e4ba55c4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestPredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# plot\n",
    "plt.plot(testPredict)\n",
    "plt.plot(testY)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2266747,
     "status": "ok",
     "timestamp": 1605677448718,
     "user": {
      "displayName": "‍김수영[학생](공과대학 산업경영공학과)",
      "photoUrl": "https://lh4.googleusercontent.com/--jvnwCNAQF4/AAAAAAAAAAI/AAAAAAAABPo/sXLQKwZm7fw/s64/photo.jpg",
      "userId": "00210890095209318843"
     },
     "user_tz": -540
    },
    "id": "AGWQN5wC3F70",
    "outputId": "227ef6b8-b453-4712-8036-daba905cc406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 19\n",
      "[0.0481539  0.04182208 0.08163265 0.05957447 0.12653061 0.11985019\n",
      " 0.05617978 0.04444444 0.03649635 0.05734767 0.0703125  0.04850746\n",
      " 0.05970149 0.05964912]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0090\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6629f851e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 39.48453140258789\n",
      "206 19\n",
      "[0.10150376 0.04240283 0.03738318 0.20908005 0.07       0.06732892\n",
      " 0.03225807 0.07193396 0.03278689 0.04363636 0.06324582 0.07565012\n",
      " 0.03089245 0.05484247]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0214\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0080\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0071\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0070\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0070\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0070\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0069\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0069\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0069\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0069\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0069\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0068\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0068\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0068\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0068\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0068\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0068\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0068\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0067\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0067\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0067\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0067\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0066\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0066\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0066\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0066\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0066\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0064\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0065\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0065\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0065\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0064\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0064\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0064\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0064\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0063\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0063\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0063\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0063\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0062\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0062\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0062\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0061\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0061\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0061\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0061\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0059\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6608bd0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 51.69296646118164\n",
      "206 19\n",
      "[0.0261194  0.07673267 0.09101517 0.09745294 0.06941177 0.04232164\n",
      " 0.03703704 0.02439024 0.01602959 0.03602484 0.01736973 0.01383648\n",
      " 0.02114428 0.04642409]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0706\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0104\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6609ad2c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 120.68580627441406\n",
      "206 19\n",
      "[0.03546099 0.03623188 0.04074074 0.0530303  0.0233463  0.03585657\n",
      " 0.02745098 0.03529412 0.06746032 0.03875969 0.04016064 0.02419355\n",
      " 0.02362205 0.02788845]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0093\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f66121732f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 151.72010803222656\n",
      "206 19\n",
      "[0.04268293 0.028125   0.06369427 0.06354515 0.05102041 0.05357143\n",
      " 0.04421769 0.03412969 0.03460208 0.03401361 0.05017921 0.07092199\n",
      " 0.09215017 0.06089744]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0213\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f660b0f5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 56.05335235595703\n",
      "206 19\n",
      "[0.03815789 0.01981506 0.04946524 0.04138852 0.06176084 0.04118404\n",
      " 0.03535353 0.0278481  0.03826531 0.02515723 0.02038217 0.02051282\n",
      " 0.03807107 0.03771131]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f661fb13ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 61.38302230834961\n",
      "206 19\n",
      "[0.04341534 0.04733728 0.04334365 0.0529595  0.03149606 0.04846527\n",
      " 0.09031199 0.03338633 0.02903226 0.02746365 0.0375817  0.04285714\n",
      " 0.03755869 0.03538462]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f661319f048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 82.12147521972656\n",
      "206 19\n",
      "[0.0191458  0.03179191 0.02971768 0.03625378 0.03353659 0.03924647\n",
      " 0.05055292 0.0371517  0.03697997 0.05503145 0.03872054 0.01683502\n",
      " 0.04975124 0.04605263]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f66178d2730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 73.18424224853516\n",
      "206 19\n",
      "[0.195231   0.06404658 0.0872093  0.09707242 0.11433172 0.11754685\n",
      " 0.05024311 0.04078303 0.06440678 0.06055646 0.08695652 0.20441989\n",
      " 0.08833333 0.06050955]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0083\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0061\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6609937b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 33.02063751220703\n",
      "206 19\n",
      "[0.03394256 0.03947368 0.04358974 0.04960835 0.02673797 0.04904632\n",
      " 0.02203857 0.03287671 0.04143646 0.04261364 0.04464286 0.03498542\n",
      " 0.02824859 0.03724928]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0107\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f66133d8048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 87.41795349121094\n",
      "206 19\n",
      "[0.03529412 0.02631579 0.0433526  0.06024096 0.09567901 0.05172414\n",
      " 0.09912536 0.08611111 0.06084656 0.06214689 0.10526316 0.05135135\n",
      " 0.08522727 0.07329843]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.4608\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.1420\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0179\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f660531bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 35.81601333618164\n",
      "206 19\n",
      "[0.06395349 0.05452436 0.06338028 0.09952607 0.04441624 0.1318822\n",
      " 0.07469879 0.04859335 0.04878049 0.06153846 0.05524862 0.06575343\n",
      " 0.04134367 0.0576671 ]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.5716\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.3981\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.2247\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0851\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0191\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0109\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0100\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0090\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0083\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0077\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0067\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0062\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0059\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f66094b4d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 25.088153839111328\n",
      "206 19\n",
      "[0.03162055 0.0242915  0.08786611 0.02845529 0.07480315 0.18928571\n",
      " 0.06024096 0.03629032 0.05349794 0.06097561 0.04761905 0.06837607\n",
      " 0.03896104 0.0338983 ]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0247\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0087\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0058\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f66063c9268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 59.87041473388672\n",
      "206 19\n",
      "[0.03873239 0.05357143 0.05375    0.07960199 0.06266667 0.05434783\n",
      " 0.03410641 0.04395604 0.04310345 0.0754717  0.08553655 0.05936073\n",
      " 0.05405405 0.05169867]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0242\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6604ea6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 36.80426788330078\n",
      "206 19\n",
      "[0.04489796 0.05782793 0.04316547 0.05907173 0.07492795 0.09734513\n",
      " 0.06317411 0.0529595  0.07389163 0.06518283 0.05389222 0.04022988\n",
      " 0.08076358 0.05769231]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0082\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6602040bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 36.11858367919922\n",
      "206 19\n",
      "[0.04046243 0.04456824 0.07122507 0.12130178 0.081571   0.10971787\n",
      " 0.06109325 0.03846154 0.06229508 0.05723906 0.08305648 0.11888112\n",
      " 0.06369427 0.06291391]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0078\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0067\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0066\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0065\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0064\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0063\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0063\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0062\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0062\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0061\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0059\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0059\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0059\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0058\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0058\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0058\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0058\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0058\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f660d69cc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 42.27523422241211\n",
      "206 19\n",
      "[0.0280112  0.03142857 0.06705539 0.03724928 0.02325581 0.02058823\n",
      " 0.02064897 0.03170029 0.02058823 0.05341246 0.05       0.02777778\n",
      " 0.02719033 0.03669725]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.3474\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.1710\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0416\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0061\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0019\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0019\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0019\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0019\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0019\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0019\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0019\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f660922a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 94.99706268310547\n",
      "206 19\n",
      "[0.05526316 0.04413793 0.05416667 0.07386364 0.05523256 0.0519084\n",
      " 0.0556369  0.04888268 0.02915452 0.08392603 0.06595092 0.07228916\n",
      " 0.04741379 0.06362379]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0352\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f66062bd730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 53.76774215698242\n",
      "206 19\n",
      "[0.02165354 0.02362205 0.06448413 0.04536489 0.025      0.05965622\n",
      " 0.02809573 0.02763562 0.11029412 0.10657596 0.06410256 0.02926209\n",
      " 0.02933673 0.03213844]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f660c8fa400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 91.25659942626953\n",
      "206 19\n",
      "[0.07948718 0.04111245 0.08875    0.04182042 0.07965686 0.11125158\n",
      " 0.31477516 0.13636364 0.13171577 0.11849192 0.08438061 0.08576998\n",
      " 0.07843137 0.07620818]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0068\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0062\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0059\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f660d395620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 32.05278396606445\n",
      "206 19\n",
      "[0.02574257 0.02302302 0.03434343 0.05821206 0.02842105 0.03961456\n",
      " 0.01902748 0.03202479 0.01691332 0.05567227 0.04008439 0.05555556\n",
      " 0.0375     0.03497942]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.1268\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0169\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f660b50c1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 85.16221618652344\n",
      "206 19\n",
      "[0.05641026 0.03576159 0.06258322 0.04854369 0.05189341 0.07638889\n",
      " 0.07438016 0.03783784 0.01915185 0.09635417 0.02857143 0.03267046\n",
      " 0.04519774 0.03983516]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0084\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0058\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6611ceba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 86.92030334472656\n",
      "206 19\n",
      "[0.05547445 0.03120357 0.04675716 0.06125574 0.07142857 0.05782313\n",
      " 0.03140496 0.02777778 0.03015075 0.06837607 0.09363296 0.08303249\n",
      " 0.0652921  0.0538336 ]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.1541\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0208\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6613169488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 64.96343231201172\n",
      "206 19\n",
      "[0.04109589 0.10414201 0.09886364 0.05       0.23303167 0.12019704\n",
      " 0.15962441 0.1010101  0.06500542 0.11933702 0.05190678 0.06148867\n",
      " 0.04901961 0.025     ]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0089\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f66109846a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 55.28565216064453\n",
      "206 19\n",
      "[0.05660377 0.08074534 0.08346457 0.12227806 0.06688418 0.09090909\n",
      " 0.05830389 0.06307978 0.13706564 0.10261194 0.1212766  0.03861789\n",
      " 0.28659794 0.11816578]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0145\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0092\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0088\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0087\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0086\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0084\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0083\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0081\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0080\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0079\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0076\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0077\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0075\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0074\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0071\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0070\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0069\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0068\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0066\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0067\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0066\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0065\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0064\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0064\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0063\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0062\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0063\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0062\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0061\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0062\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0062\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0062\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0061\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0061\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0059\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0059\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0059\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f660b8e3e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 39.928951263427734\n",
      "206 19\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0165\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0111\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0100\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0092\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0086\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0082\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0079\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0076\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0071\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0070\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0068\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0067\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0066\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0064\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0064\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0062\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0061\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0061\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0059\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0059\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0058\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0058\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0058\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f66166922f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : inf\n",
      "206 19\n",
      "[0.05076142 0.06994819 0.04404145 0.08184143 0.02763819 0.04580153\n",
      " 0.05585106 0.04871795 0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6609480488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : inf\n",
      "206 19\n",
      "[0.0430622  0.10294118 0.06583428 0.07629108 0.05315204 0.04260652\n",
      " 0.09768638 0.06690998 0.115      0.11022727 0.06632653 0.10087173\n",
      " 0.03872437 0.09953704]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
      "101/101 - 0s - loss: 0.0078\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0061\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f660615c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 72.0901107788086\n",
      "206 19\n",
      "[0.01939058 0.03457815 0.05       0.03901734 0.02976191 0.02949853\n",
      " 0.0376506  0.03047895 0.03880597 0.05640244 0.05483871 0.0549273\n",
      " 0.04441041 0.04538341]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6601922c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 49.586265563964844\n",
      "206 19\n",
      "[0.09341501 0.05       0.12202853 0.05808477 0.05828221 0.06687898\n",
      " 0.04477612 0.05901639 0.05025996 0.05       0.09481217 0.06643357\n",
      " 0.05263158 0.07060755]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0310\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f660348a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 20.05406379699707\n",
      "206 19\n",
      "[0.02189781 0.05378973 0.04578313 0.03960396 0.05263158 0.10591133\n",
      " 0.02955665 0.0313253  0.0275     0.04126214 0.06818182 0.03655353\n",
      " 0.05483029 0.05445545]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f65fda196a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 71.78199768066406\n",
      "206 19\n",
      "[0.04278075 0.02727273 0.0498155  0.08067542 0.06142035 0.05154639\n",
      " 0.05015045 0.06614786 0.03494347 0.08033827 0.07283237 0.0896861\n",
      " 0.05063291 0.04944501]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.4215\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.1906\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0160\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0081\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0019\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0019\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0019\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0019\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0018\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0019\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0019\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0019\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0019\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0018\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0018\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0018\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0018\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0018\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0018\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0018\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0017\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0018\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0018\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0018\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0017\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0017\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0017\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0017\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0017\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0017\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0017\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0017\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6629fa80d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 29.37883186340332\n",
      "206 19\n",
      "[0.07343941 0.0653753  0.0753828  0.06097561 0.04671717 0.0357599\n",
      " 0.02130326 0.05800757 0.04145078 0.04798962 0.02818792 0.03342246\n",
      " 0.03448276 0.01968504]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.2219\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.1015\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0289\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0078\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0019\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0019\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0018\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0018\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0018\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0018\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0017\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0017\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0017\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0017\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0017\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0016\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f661fb0a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 64.64307403564453\n",
      "206 19\n",
      "[0.0498155  0.06844106 0.0625     0.04216868 0.04554455 0.07355865\n",
      " 0.02798508 0.04364326 0.04952381 0.05128205 0.05697446 0.046875\n",
      " 0.03422053 0.06382979]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6608c80598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 41.77057647705078\n",
      "206 19\n",
      "[0.11258278 0.05970149 0.05740181 0.08895705 0.13030303 0.1056338\n",
      " 0.03618421 0.06040268 0.06484642 0.04067797 0.08445946 0.07857143\n",
      " 0.03030303 0.02730375]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6603513510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 55.553466796875\n",
      "206 19\n",
      "[0.04878049 0.03597122 0.05576208 0.04285714 0.04693141 0.04135338\n",
      " 0.0326087  0.02919708 0.02621723 0.06439394 0.0661157  0.05691057\n",
      " 0.04453441 0.04651163]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0014\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0015\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6613169048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 61.78007125854492\n",
      "206 19\n",
      "[0.05639913 0.05777778 0.05800464 0.05582524 0.07444169 0.05502392\n",
      " 0.05660377 0.02985075 0.0302267  0.07341772 0.03350516 0.05194805\n",
      " 0.03535353 0.03376623]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f660613be18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 61.950008392333984\n",
      "206 19\n",
      "[0.05761317 0.05838641 0.05531453 0.07650273 0.04255319 0.04941177\n",
      " 0.04205607 0.05359179 0.02160864 0.10131108 0.10104987 0.12030075\n",
      " 0.06620209 0.06688963]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0075\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6611e43a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 34.170101165771484\n",
      "206 19\n",
      "[0.08962264 0.04402516 0.12643678 0.06901841 0.0585443  0.06543624\n",
      " 0.05150977 0.02936097 0.10915493 0.08163265 0.06239737 0.03821656\n",
      " 0.03633491 0.05254777]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f661046b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 49.706764221191406\n",
      "206 19\n",
      "[0.08851675 0.08213097 0.05882353 0.07783019 0.11097852 0.1024735\n",
      " 0.10656753 0.18680089 0.23175416 0.17230098 0.12835821 0.18081588\n",
      " 0.07065217 0.06471816]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.2750\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0472\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0069\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6608ac58c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 32.77714920043945\n",
      "206 19\n",
      "[0.05342237 0.04313099 0.03618421 0.05564924 0.01870748 0.06842105\n",
      " 0.02664298 0.04020979 0.02998236 0.04918033 0.0341556  0.04474708\n",
      " 0.03358209 0.03213611]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6606ef2268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 78.94737243652344\n",
      "206 19\n",
      "[0.05033557 0.04655172 0.07027027 0.05516014 0.06884058 0.0459364\n",
      " 0.07692308 0.03092784 0.03275862 0.07008547 0.03488372 0.03505843\n",
      " 0.03770492 0.07432432]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6604e82f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 56.47990798950195\n",
      "206 19\n",
      "[0.03361344 0.03813559 0.05627706 0.03571429 0.05405405 0.0456621\n",
      " 0.03271028 0.15837104 0.05       0.08154506 0.03773585 0.03921569\n",
      " 0.05392157 0.03349282]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0095\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0076\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0074\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0074\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0074\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0074\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0074\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0071\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f65ff9f52f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 41.761356353759766\n",
      "206 19\n",
      "[0.0261194  0.02661597 0.04280156 0.04247104 0.02390438 0.048583\n",
      " 0.0204918  0.03252033 0.0373444  0.05063291 0.05309734 0.04054054\n",
      " 0.03043478 0.02192983]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0485\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0063\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6609850620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 125.0029296875\n",
      "206 19\n",
      "[0.03833866 0.02715655 0.09531502 0.05654281 0.05149502 0.03940887\n",
      " 0.03225807 0.02580645 0.03548387 0.03934426 0.05792163 0.01976936\n",
      " 0.05691057 0.03630363]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0340\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0065\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f65fd04b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 77.74620056152344\n",
      "206 19\n",
      "[0.08037825 0.03217822 0.04545454 0.04960835 0.05851064 0.06036745\n",
      " 0.04864865 0.03617571 0.03598972 0.0631579  0.05866667 0.04155125\n",
      " 0.04289544 0.02997275]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.4394\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.3033\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.1659\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0596\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0158\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0114\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0099\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0086\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0075\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0066\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0059\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f660178be18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 27.730880737304688\n",
      "206 19\n",
      "[0.0330993  0.02970297 0.07099392 0.04724409 0.02667984 0.04077472\n",
      " 0.07723996 0.03069307 0.06006006 0.11589744 0.0741573  0.02054795\n",
      " 0.07877462 0.03539823]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0080\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0063\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f65ff67b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 68.39720153808594\n",
      "206 19\n",
      "[0.02359551 0.06342016 0.04139434 0.05980066 0.04671858 0.0437788\n",
      " 0.04452467 0.07920792 0.09481669 0.03780488 0.05343511 0.08114856\n",
      " 0.07429245 0.06703911]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0716\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0073\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f65fd395950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 44.52528762817383\n",
      "206 19\n",
      "[0.05405405 0.02727273 0.09259259 0.09756098 0.05555556 0.05574913\n",
      " 0.03859649 0.0625     0.01811594 0.08214286 0.05836576 0.04230769\n",
      " 0.04545454 0.02930403]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0058\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f65fb3abe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 75.2845230102539\n",
      "206 19\n",
      "[0.10088692 0.04066736 0.0539112  0.04909285 0.15824176 0.06846473\n",
      " 0.09820486 0.061      0.16788321 0.09859155 0.098      0.09868421\n",
      " 0.07759563 0.05379747]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0156\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0109\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0087\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0070\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6605371d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 38.74381637573242\n",
      "206 19\n",
      "[0.06       0.08571429 0.28471248 0.16856061 0.07775591 0.05555556\n",
      " 0.041      0.04906054 0.03974895 0.09304704 0.14576271 0.08658009\n",
      " 0.08062827 0.053     ]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0515\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0088\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0079\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0068\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0065\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0062\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0061\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0060\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0058\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6612f33598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 56.162052154541016\n",
      "206 19\n",
      "[0.04074074 0.02264151 0.02671756 0.04135338 0.03846154 0.0233463\n",
      " 0.03846154 0.02264151 0.03041825 0.02583026 0.03358209 0.03501945\n",
      " 0.03787879 0.03474903]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0021\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0020\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f65ff46f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 90.83958435058594\n",
      "206 19\n",
      "[0.03341289 0.0315534  0.0920398  0.07329843 0.28021978 0.11347518\n",
      " 0.09043928 0.03740648 0.19845361 0.11002445 0.04285714 0.2853598\n",
      " 0.1793722  0.06410256]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0742\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0068\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0059\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f66073eae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 56.123634338378906\n",
      "206 19\n",
      "[0.02478315 0.05296343 0.07898089 0.08203125 0.12637363 0.04613297\n",
      " 0.05809129 0.03814714 0.04178273 0.0746888  0.09402985 0.01903367\n",
      " 0.03328509 0.06231884]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0068\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6601bbcae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 79.1469955444336\n",
      "206 19\n",
      "[0.07692308 0.08171206 0.06910569 0.09166667 0.08119658 0.0840708\n",
      " 0.03947368 0.07589286 0.04265403 0.04390244 0.05876393 0.071\n",
      " 0.06074766 0.04830918]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.3855\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0098\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6607160510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 34.383644104003906\n",
      "206 19\n",
      "[0.19008264 0.06376812 0.10385757 0.0781759  0.06418919 0.06859206\n",
      " 0.03484321 0.06737589 0.04166667 0.08270677 0.07692308 0.0390625\n",
      " 0.12109375 0.05639098]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0085\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0076\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0070\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0065\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0062\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0059\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0058\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0056\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0055\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0052\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6606c37378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 46.27678680419922\n",
      "206 19\n",
      "[0.04018912 0.03406326 0.085      0.04780362 0.29961089 0.17118998\n",
      " 0.11694511 0.06993007 0.23776224 0.14923747 0.08333333 0.29861849\n",
      " 0.27598566 0.1121643 ]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0116\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f66085402f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 52.443485260009766\n",
      "206 19\n",
      "[0.08008899 0.0880829  0.07013815 0.0377551  0.04726891 0.06126915\n",
      " 0.04314995 0.03191489 0.07626208 0.09216921 0.07711757 0.09228824\n",
      " 0.05180723 0.05889146]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0285\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6611ceb510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 61.72957992553711\n",
      "206 19\n",
      "[0.04022191 0.04742547 0.03835979 0.09733333 0.02762431 0.05586592\n",
      " 0.01980198 0.04107649 0.0189781  0.05959302 0.04205607 0.046875\n",
      " 0.03647416 0.05451713]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f661f4d12f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 86.14022064208984\n",
      "206 19\n",
      "[0.10065646 0.11001965 0.05644302 0.09090909 0.06462213 0.06436782\n",
      " 0.03510759 0.06333333 0.03904555 0.07897664 0.05346294 0.05090909\n",
      " 0.06690998 0.03180212]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0365\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0072\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f660bf7b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 37.019344329833984\n",
      "206 19\n",
      "[0.0754717  0.07641196 0.04659498 0.07885305 0.05681818 0.05747126\n",
      " 0.02631579 0.05992509 0.02811245 0.14170041 0.09090909 0.07083333\n",
      " 0.03614458 0.08097166]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0269\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6603142e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 46.36667251586914\n",
      "206 19\n",
      "[0.08127208 0.08717949 0.04746318 0.1442623  0.16335878 0.10081744\n",
      " 0.12608696 0.17457887 0.08382353 0.08545727 0.06557377 0.09047619\n",
      " 0.09930314 0.07526882]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0068\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f66069de048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 45.62716293334961\n",
      "206 19\n",
      "[0.04690619 0.19341564 0.09768379 0.06060606 0.05363985 0.058\n",
      " 0.03769841 0.1613806  0.10228509 0.06352941 0.08809524 0.04390244\n",
      " 0.10977081 0.03325942]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6601a0d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 38.181312561035156\n",
      "206 19\n",
      "[0.02962963 0.02727273 0.04411765 0.08118081 0.01923077 0.04861111\n",
      " 0.05       0.04797048 0.02702703 0.03824092 0.044      0.05125628\n",
      " 0.03754941 0.04109589]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6602a52ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 72.63117218017578\n",
      "206 19\n",
      "[0.05268935 0.09841629 0.07074974 0.04042553 0.03695652 0.07333333\n",
      " 0.03794643 0.06847826 0.07724426 0.06060606 0.10376283 0.03538813\n",
      " 0.06825939 0.05957944]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0242\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6602395048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 33.55954360961914\n",
      "206 19\n",
      "[0.02091021 0.02702703 0.0622665  0.14705882 0.07960199 0.08717949\n",
      " 0.03506493 0.03896104 0.04450262 0.04697987 0.05135521 0.02361111\n",
      " 0.03125    0.03107345]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.4820\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0952\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0086\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0068\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0059\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f65fa5e9378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 114.96012878417969\n",
      "206 19\n",
      "[0.0263789  0.06443914 0.06728538 0.08495146 0.03562341 0.0546875\n",
      " 0.03376623 0.02820513 0.03598972 0.03457447 0.04432133 0.03571429\n",
      " 0.04132231 0.02680965]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0061\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f65f90449d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 114.22867584228516\n",
      "206 19\n",
      "[0.04523809 0.04895105 0.09352518 0.05188679 0.02981651 0.03554502\n",
      " 0.06904762 0.10489511 0.06798246 0.06196581 0.04148472 0.05405405\n",
      " 0.03991131 0.05353319]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f660b5aaf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 31.97834587097168\n",
      "206 19\n",
      "[0.0729927  0.15965167 0.14944134 0.09020619 0.05776637 0.04907162\n",
      " 0.04258065 0.19230769 0.06472919 0.09803922 0.05287714 0.1201849\n",
      " 0.03488372 0.06231884]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0067\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0054\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0050\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0047\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0032\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0031\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6604e829d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 36.97557830810547\n",
      "206 19\n",
      "[0.02787879 0.0169697  0.05804111 0.06060606 0.02331606 0.07702182\n",
      " 0.06274008 0.0245098  0.0325     0.05534591 0.04133333 0.01634877\n",
      " 0.06948229 0.03141361]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.1513\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0389\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0092\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0076\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0068\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0062\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0053\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0051\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0048\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0046\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0045\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0044\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0043\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0041\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0040\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0039\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0038\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0037\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0035\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f65f86391e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 100.0438232421875\n",
      "206 19\n",
      "[0.02050114 0.02325581 0.05827506 0.06557377 0.03544304 0.05693069\n",
      " 0.06075949 0.06024096 0.040201   0.0546875  0.07162534 0.03457447\n",
      " 0.04123711 0.03439153]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.2166\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0936\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0286\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0172\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0150\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0130\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0114\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0100\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0086\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0075\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0065\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0057\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0049\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0042\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0036\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0033\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f65fa882730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 67.56023406982422\n",
      "206 19\n",
      "[0.01554404 0.04398448 0.05929919 0.11142857 0.04413793 0.06125356\n",
      " 0.03644315 0.02312139 0.02218935 0.07843137 0.06260296 0.02060222\n",
      " 0.0328125  0.06656101]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.0034\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.0030\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.0029\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.0028\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0027\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0026\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0025\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0024\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0023\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0022\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f65fd77f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 96.01671600341797\n",
      "206 19\n",
      "[0.62347188 0.61124694 0.46943765 0.11271394 0.58679707 0.60635697\n",
      " 0.58924205 0.45232274 0.11760391 0.61858191 0.62836186 0.63325183\n",
      " 0.46943765 0.12200489]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 0.3568\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 0.2647\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 0.1972\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 0.1464\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 0.1107\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 0.0875\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 0.0721\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 0.0616\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 0.0534\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 0.0467\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 0.0416\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 0.0378\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 0.0350\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 0.0329\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 0.0312\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 0.0296\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 0.0283\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 0.0270\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 0.0257\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 0.0247\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 0.0236\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 0.0227\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 0.0220\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 0.0213\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 0.0207\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 0.0201\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 0.0197\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 0.0191\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 0.0186\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 0.0182\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 0.0177\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 0.0173\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 0.0169\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 0.0165\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 0.0161\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 0.0157\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 0.0154\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 0.0150\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 0.0146\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 0.0143\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 0.0138\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 0.0137\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 0.0133\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 0.0131\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 0.0129\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 0.0127\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 0.0124\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 0.0121\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 0.0119\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 0.0117\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6606b377b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 101.12535858154297\n",
      "206 19\n",
      "[4.40140054 4.40654018 4.39794001 4.28330123 4.39093511 4.38021124\n",
      " 4.39445168 4.38201704 4.26717173 4.40993312 4.40312052 4.40993312\n",
      " 4.41329976 4.28330123]\n",
      "Epoch 1/50\n",
      "101/101 - 0s - loss: 16.6471\n",
      "Epoch 2/50\n",
      "101/101 - 0s - loss: 15.8798\n",
      "Epoch 3/50\n",
      "101/101 - 0s - loss: 15.1223\n",
      "Epoch 4/50\n",
      "101/101 - 0s - loss: 14.2409\n",
      "Epoch 5/50\n",
      "101/101 - 0s - loss: 13.0183\n",
      "Epoch 6/50\n",
      "101/101 - 0s - loss: 11.4761\n",
      "Epoch 7/50\n",
      "101/101 - 0s - loss: 10.5923\n",
      "Epoch 8/50\n",
      "101/101 - 0s - loss: 10.3786\n",
      "Epoch 9/50\n",
      "101/101 - 0s - loss: 10.3077\n",
      "Epoch 10/50\n",
      "101/101 - 0s - loss: 10.2645\n",
      "Epoch 11/50\n",
      "101/101 - 0s - loss: 10.2356\n",
      "Epoch 12/50\n",
      "101/101 - 0s - loss: 10.2161\n",
      "Epoch 13/50\n",
      "101/101 - 0s - loss: 10.2024\n",
      "Epoch 14/50\n",
      "101/101 - 0s - loss: 10.1931\n",
      "Epoch 15/50\n",
      "101/101 - 0s - loss: 10.1868\n",
      "Epoch 16/50\n",
      "101/101 - 0s - loss: 10.1825\n",
      "Epoch 17/50\n",
      "101/101 - 0s - loss: 10.1794\n",
      "Epoch 18/50\n",
      "101/101 - 0s - loss: 10.1774\n",
      "Epoch 19/50\n",
      "101/101 - 0s - loss: 10.1759\n",
      "Epoch 20/50\n",
      "101/101 - 0s - loss: 10.1749\n",
      "Epoch 21/50\n",
      "101/101 - 0s - loss: 10.1741\n",
      "Epoch 22/50\n",
      "101/101 - 0s - loss: 10.1734\n",
      "Epoch 23/50\n",
      "101/101 - 0s - loss: 10.1728\n",
      "Epoch 24/50\n",
      "101/101 - 0s - loss: 10.1723\n",
      "Epoch 25/50\n",
      "101/101 - 0s - loss: 10.1718\n",
      "Epoch 26/50\n",
      "101/101 - 0s - loss: 10.1713\n",
      "Epoch 27/50\n",
      "101/101 - 0s - loss: 10.1708\n",
      "Epoch 28/50\n",
      "101/101 - 0s - loss: 10.1702\n",
      "Epoch 29/50\n",
      "101/101 - 0s - loss: 10.1697\n",
      "Epoch 30/50\n",
      "101/101 - 0s - loss: 10.1691\n",
      "Epoch 31/50\n",
      "101/101 - 0s - loss: 10.1684\n",
      "Epoch 32/50\n",
      "101/101 - 0s - loss: 10.1677\n",
      "Epoch 33/50\n",
      "101/101 - 0s - loss: 10.1670\n",
      "Epoch 34/50\n",
      "101/101 - 0s - loss: 10.1666\n",
      "Epoch 35/50\n",
      "101/101 - 0s - loss: 10.1662\n",
      "Epoch 36/50\n",
      "101/101 - 0s - loss: 10.1656\n",
      "Epoch 37/50\n",
      "101/101 - 0s - loss: 10.1651\n",
      "Epoch 38/50\n",
      "101/101 - 0s - loss: 10.1650\n",
      "Epoch 39/50\n",
      "101/101 - 0s - loss: 10.1648\n",
      "Epoch 40/50\n",
      "101/101 - 0s - loss: 10.1644\n",
      "Epoch 41/50\n",
      "101/101 - 0s - loss: 10.1642\n",
      "Epoch 42/50\n",
      "101/101 - 0s - loss: 10.1642\n",
      "Epoch 43/50\n",
      "101/101 - 0s - loss: 10.1641\n",
      "Epoch 44/50\n",
      "101/101 - 0s - loss: 10.1638\n",
      "Epoch 45/50\n",
      "101/101 - 0s - loss: 10.1637\n",
      "Epoch 46/50\n",
      "101/101 - 0s - loss: 10.1636\n",
      "Epoch 47/50\n",
      "101/101 - 0s - loss: 10.1636\n",
      "Epoch 48/50\n",
      "101/101 - 0s - loss: 10.1634\n",
      "Epoch 49/50\n",
      "101/101 - 0s - loss: 10.1635\n",
      "Epoch 50/50\n",
      "101/101 - 0s - loss: 10.1634\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f660edf7c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAPE : 77.13105773925781\n",
      "                mape\n",
      "두산중공업      39.484531\n",
      "쌍용자동차      51.692966\n",
      "KG동부제철    120.685806\n",
      "에이프로젠제약   151.720108\n",
      "현대일렉트릭     56.053352\n",
      "...              ...\n",
      "MH에탄올     100.043823\n",
      "센트랄모텍      67.560234\n",
      "두산솔루스      96.016716\n",
      "뉴스빈도      101.125359\n",
      "뉴스빈도_log   77.131058\n",
      "\n",
      "[122 rows x 1 columns]\n",
      "             mape\n",
      "count  122.000000\n",
      "mean    65.972410\n",
      "std     32.577917\n",
      "min      0.000000\n",
      "25%     42.526091\n",
      "50%     60.546583\n",
      "75%     81.503616\n",
      "max    231.753738\n"
     ]
    }
   ],
   "source": [
    "col=list(data1.columns)\n",
    "mape_val=[]\n",
    "for company in col:\n",
    "  pandf_train = pd.DataFrame(data1, columns=[ company , \"뉴스빈도_log\"])\n",
    "  pandf_test = pd.DataFrame(data2, columns=[ company , \"뉴스빈도_log\"])\n",
    "\n",
    "\n",
    "  # convert nparray # split train, test\n",
    "  train = pandf_train.values\n",
    "  train.astype('float32')\n",
    "  test = pandf_test.values\n",
    "  test.astype('float32')\n",
    "  print(len(train), len(test))\n",
    "\n",
    "  # create dataset for learning\n",
    "  trainX, trainY = create_dataset(train, look_back)\n",
    "  testX, testY = create_dataset(test, look_back)\n",
    "  print(testY)\n",
    "  # reshape input to be [samples, time steps, features]\n",
    "  trainX = np.reshape(trainX, (trainX.shape[0], look_back, columns))\n",
    "  testX = np.reshape(testX, (testX.shape[0], look_back, columns))\n",
    "\n",
    "\n",
    "\n",
    "  # simple lstm network learning\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(1, input_shape=(look_back, columns)))   \n",
    "\n",
    "  model.add(Dense(1,activation='tanh'))\n",
    "  model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "  model.fit(trainX, trainY, epochs=50, batch_size=2, verbose=2)\n",
    "\n",
    "  #print(testPredict)\n",
    "  #print(testY)\n",
    "  testPredict = model.predict(testX)\n",
    "  testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "  sum=0\n",
    "  for i in range(len(testY)):\n",
    "    sum+=abs((testY[i]-testPredict[i])/testY[i])\n",
    "\n",
    "  mape=100*sum/int(len(testY))\n",
    "  print('MAPE :',float(mape))\n",
    "  mape_val.append(mape)\n",
    "\n",
    "m_val=[]\n",
    "for i in mape_val:\n",
    "  if i==float('inf'):\n",
    "    m_val.append(0)\n",
    "  else:\n",
    "    m_val.append(float(i))\n",
    "\n",
    "evaluate=pd.DataFrame({'mape':m_val},index=col)\n",
    "\n",
    "print(evaluate)\n",
    "print(evaluate.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 802,
     "status": "ok",
     "timestamp": 1605668310748,
     "user": {
      "displayName": "‍김수영[학생](공과대학 산업경영공학과)",
      "photoUrl": "https://lh4.googleusercontent.com/--jvnwCNAQF4/AAAAAAAAAAI/AAAAAAAABPo/sXLQKwZm7fw/s64/photo.jpg",
      "userId": "00210890095209318843"
     },
     "user_tz": -540
    },
    "id": "wQe6SFdQASBJ",
    "outputId": "e01ff2d5-d3ca-4469-fc14-b26cbdcf8266"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.301130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.044561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37.139424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48.298094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>65.300323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>131.327316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mape\n",
       "count  120.000000\n",
       "mean    54.301130\n",
       "std     24.044561\n",
       "min      0.000000\n",
       "25%     37.139424\n",
       "50%     48.298094\n",
       "75%     65.300323\n",
       "max    131.327316"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate=evaluate.drop(['뉴스빈도'])\n",
    "evaluate.describe()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Rnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
